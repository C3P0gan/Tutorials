{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corretor Ortográfico em Python: aplicando técnicas de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Explorando um projeto de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Importando um corpus textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nimagem \\n\\nTemos a seguinte classe que representa um usuário no nosso sistema:\\n\\njava\\n\\nPara salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\\n\\njava \\n\\nSuponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"dados/artigos.txt\") as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "artigos[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['Olá,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "texto_exemplo = \"Olá, tudo bem?\"\n",
    "tokens = texto_exemplo.split(\" \")\n",
    "print(len(tokens))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Utilizando NLTK para tokenizar um texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Refinando a tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Natural Language Toolkit - NLTK](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem',\n",
       " 'Temos',\n",
       " 'a',\n",
       " 'seguinte',\n",
       " 'classe',\n",
       " 'que',\n",
       " 'representa',\n",
       " 'um',\n",
       " 'usuário',\n",
       " 'no',\n",
       " 'nosso',\n",
       " 'sistema',\n",
       " ':',\n",
       " 'java',\n",
       " 'Para',\n",
       " 'salvar',\n",
       " 'um',\n",
       " 'novo',\n",
       " 'usuário',\n",
       " ',',\n",
       " 'várias',\n",
       " 'validações',\n",
       " 'são',\n",
       " 'feitas',\n",
       " ',',\n",
       " 'como',\n",
       " 'por',\n",
       " 'exemplo',\n",
       " ':',\n",
       " 'Ver',\n",
       " 'se',\n",
       " 'o',\n",
       " 'nome',\n",
       " 'só',\n",
       " 'contém',\n",
       " 'letras',\n",
       " ',',\n",
       " '[',\n",
       " '*',\n",
       " '*',\n",
       " 'o',\n",
       " 'CPF',\n",
       " 'só',\n",
       " 'números',\n",
       " '*',\n",
       " '*',\n",
       " ']',\n",
       " 'e',\n",
       " 'ver',\n",
       " 'se']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_tokens[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Separando palavras de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def separa_palavras(lista_tokens: List[str]) -> List[str]:\n",
    "    lista_palavras = list()\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. Contando palavras do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403104"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "len(lista_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06. Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao(lista_palavras: List[str]) -> List[str]:\n",
    "    lista_normalizada = list()\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem', 'temos', 'a', 'seguinte', 'classe']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "lista_normalizada[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07. Tipos de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465\n"
     ]
    }
   ],
   "source": [
    "print(len(set(lista_normalizada)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Desenvolvendo e testando o corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Fatiando strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavra_exemplo = \"lgica\"\n",
    "\n",
    "def gerador_palavras(palavra: str) -> List[str]:\n",
    "    fatias = list()\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    print(fatias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 'lgica'), ('l', 'gica'), ('lg', 'ica'), ('lgi', 'ca'), ('lgic', 'a'), ('lgica', '')]\n"
     ]
    }
   ],
   "source": [
    "gerador_palavras(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Operação de inserção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def insere_letras(fatias: List[Tuple]) -> List:\n",
    "    novas_palavras = list()\n",
    "    letras = \"abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôòõúûùũç\"\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerador_palavras(palavra: str) -> List[str]:\n",
    "    def insere_letras(fatias: List[Tuple]) -> List:\n",
    "        novas_palavras = list()\n",
    "        letras = \"abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôòõúûùũç\"\n",
    "        for E, D in fatias:\n",
    "            for letra in letras:\n",
    "                novas_palavras.append(E + letra + D)\n",
    "        return novas_palavras\n",
    "\n",
    "    fatias = list()\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algica',\n",
       " 'blgica',\n",
       " 'clgica',\n",
       " 'dlgica',\n",
       " 'elgica',\n",
       " 'flgica',\n",
       " 'glgica',\n",
       " 'hlgica',\n",
       " 'ilgica',\n",
       " 'jlgica']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerador_palavras(palavra_exemplo)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06. Construindo a função corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra: str) -> str:\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07. Probabilidade das palavras geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(palavra_gerada: str):\n",
    "    return frequencia[palavra_gerada]/total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra: str) -> str:\n",
    "    def probabilidade(palavra_gerada: str):\n",
    "        return frequencia[palavra_gerada]/total_palavras\n",
    "\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Avaliando a qualidade do corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Preparando dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo: str) -> List[str]:\n",
    "    lista_palavras_teste = list()\n",
    "    f = open(nome_arquivo, \"r\")\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split(\" \")\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos\\n'),\n",
       " ('esse', 'esje\\n'),\n",
       " ('já', 'jrá\\n'),\n",
       " ('nosso', 'nossov\\n'),\n",
       " ('são', 'sãêo\\n'),\n",
       " ('dos', 'dosa\\n'),\n",
       " ('muito', 'muifo\\n'),\n",
       " ('imagem', 'iômagem\\n'),\n",
       " ('sua', 'ósua\\n'),\n",
       " ('também', 'tambéùm\\n')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_teste = cria_dados_teste(\"./dados/palavras.txt\")\n",
    "lista_teste[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Avaliando o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador(testes: List[str]) -> None:\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
